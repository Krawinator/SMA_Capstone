{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05001759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading JSONL: 260it [00:00, 61859.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding 260 documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:01<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Index built with 260 vectors.\n",
      "Search engine index built and saved.\n",
      "1. LPT If you're an introvert, you don’t need to force yourself to become an extrovert to make friends—just embrace your natural traits. → https://www.reddit.com/r/LifeProTips/comments/1jchdg1/lpt_if_youre_an_introvert_you_dont_need_to_force/ (score: 0.416)\n",
      "2. LPT - When preparing for a job interview, record yourself. → https://www.reddit.com/r/LifeProTips/comments/1j6jklq/lpt_when_preparing_for_a_job_interview_record/ (score: 0.369)\n",
      "3. LPT: If you're learning any new skill, don't compare your beginning to someone else's middle. Everyone starts somewhere, and consistent practice matters more than natural talent. → https://www.reddit.com/r/LifeProTips/comments/1khlczv/lpt_if_youre_learning_any_new_skill_dont_compare/ (score: 0.341)\n",
      "4. LPT Request: How to deal with stress before giving a presentation? → https://www.reddit.com/r/LifeProTips/comments/1k7mdc5/lpt_request_how_to_deal_with_stress_before_giving/ (score: 0.330)\n",
      "5. LPT Request-I wish I could feel comfortable in front of the camera. → https://www.reddit.com/r/LifeProTips/comments/1k7hisi/lpt_requesti_wish_i_could_feel_comfortable_in/ (score: 0.297)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "semantic_search_engine.py\n",
    "\n",
    "A modular semantic search engine for a Reddit life-advice corpus.\n",
    "\n",
    "This version is configured for interactive use in notebooks.\n",
    "It loads a dataset from a hardcoded path and builds the FAISS index.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "from __future__ import annotations\n",
    "import json, os, pickle, textwrap\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(x, *args, **kwargs): return x\n",
    "\n",
    "class SemanticSearchEngine:\n",
    "    def __init__(self,\n",
    "                 model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                 index_dir: str | Path = \"index\",\n",
    "                 use_gpu: bool = False):\n",
    "        self.index_dir = Path(index_dir)\n",
    "        self.index_path = self.index_dir / \"faiss.index\"\n",
    "        self.meta_path = self.index_dir / \"metadata.pkl\"\n",
    "        self.index_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        if use_gpu:\n",
    "            self.model = self.model.to(\"cuda\")\n",
    "\n",
    "        self.index: faiss.Index | None = None\n",
    "        self.metadata: List[Dict] = []\n",
    "\n",
    "    @staticmethod\n",
    "    def _normalise(emb: np.ndarray) -> np.ndarray:\n",
    "        norm = np.linalg.norm(emb, axis=1, keepdims=True)\n",
    "        return emb / np.maximum(norm, 1e-12)\n",
    "\n",
    "    def build(self, docs: List[str], metas: List[Dict], hnsw_m: int = 32):\n",
    "        if len(docs) != len(metas):\n",
    "            raise ValueError(\"Mismatch between docs and metas\")\n",
    "\n",
    "        print(f\"Encoding {len(docs)} documents...\")\n",
    "        embeddings = self.model.encode(docs, batch_size=128, show_progress_bar=True, convert_to_numpy=True)\n",
    "        embeddings = self._normalise(embeddings.astype('float32'))\n",
    "\n",
    "        dim = embeddings.shape[1]\n",
    "        self.index = faiss.IndexHNSWFlat(dim, hnsw_m, faiss.METRIC_INNER_PRODUCT)\n",
    "        self.index.hnsw.efConstruction = 200\n",
    "\n",
    "        self.index.add(embeddings)\n",
    "        self.metadata = metas\n",
    "        self.save()\n",
    "        print(f\"✓ Index built with {self.index.ntotal} vectors.\")\n",
    "\n",
    "    def save(self):\n",
    "        faiss.write_index(self.index, str(self.index_path))\n",
    "        with open(self.meta_path, \"wb\") as f:\n",
    "            pickle.dump(self.metadata, f)\n",
    "\n",
    "    def load(self):\n",
    "        if self.index is None:\n",
    "            self.index = faiss.read_index(str(self.index_path))\n",
    "        if not self.metadata:\n",
    "            with open(self.meta_path, \"rb\") as f:\n",
    "                self.metadata = pickle.load(f)\n",
    "\n",
    "    def search(self, query: str, top_k: int = 5) -> List[Dict]:\n",
    "        self.load()\n",
    "        q_emb = self.model.encode([query], convert_to_numpy=True)\n",
    "        q_emb = self._normalise(q_emb.astype('float32'))\n",
    "\n",
    "        scores, idxs = self.index.search(q_emb, top_k)\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], idxs[0]):\n",
    "            item = self.metadata[idx].copy()\n",
    "            item[\"score\"] = float(score)\n",
    "            results.append(item)\n",
    "        return results\n",
    "\n",
    "    def rag_answer(self, query: str, context_k: int = 5, model: str = \"gpt-3.5-turbo-0125\",\n",
    "                   openai_api_key: str | None = None) -> str:\n",
    "        import openai\n",
    "\n",
    "        openai.api_key = openai_api_key or os.getenv(\"OPENAI_API_KEY\")\n",
    "        if not openai.api_key:\n",
    "            raise EnvironmentError(\"OPENAI_API_KEY not set\")\n",
    "\n",
    "        contexts = self.search(query, top_k=context_k)\n",
    "        concatenated = \"\\n\\n\".join(\n",
    "            f\"Title: {c['title']}\\nAdvice: {c.get('top_comment', 'N/A')}\\nURL: {c['url']}\"\n",
    "            for c in contexts\n",
    "        )\n",
    "\n",
    "        system_prompt = \"You are a friendly assistant who provides concise, actionable life advice.\"\n",
    "        user_prompt = (\n",
    "            f\"Based on the Reddit advice below, answer the QUESTION in 3–5 bullet points.\\n\\n\"\n",
    "            f\"REDDIT ADVICE:\\n{concatenated}\\n\\nQUESTION: {query}\"\n",
    "        )\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                      {\"role\": \"user\", \"content\": user_prompt}],\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        return textwrap.fill(response.choices[0].message.content.strip(), 100)\n",
    "\n",
    "\n",
    "def parse_reddit_jsonl(path: str) -> tuple[List[str], List[Dict]]:\n",
    "    docs, metas = [], []\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as fh:\n",
    "        for line in tqdm(fh, desc=\"Reading JSONL\"):\n",
    "            item = json.loads(line)\n",
    "            title = item.get(\"title\", \"\").strip()\n",
    "            selftext = item.get(\"selftext\", \"\").strip()\n",
    "            comments = item.get(\"comments\", [])\n",
    "            comment_str = \" \".join(comments).strip()\n",
    "\n",
    "            full_text = \" \".join([title, selftext, comment_str]).strip()\n",
    "\n",
    "            metas.append({\n",
    "                \"title\": title or full_text[:60] + \"…\",\n",
    "                \"url\": item.get(\"url\"),\n",
    "                \"post_score\": item.get(\"score\", 0),\n",
    "                \"subreddit\": item.get(\"subreddit\", \"\"),\n",
    "                \"created_utc\": item.get(\"created_utc\"),\n",
    "                \"top_comment\": comments[0] if comments else \"\",\n",
    "            })\n",
    "            docs.append(full_text)\n",
    "    return docs, metas\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = \"reddit_wisdom_data.jsonl\"\n",
    "\n",
    "    engine = SemanticSearchEngine(index_dir=\"index\")\n",
    "    docs, metas = parse_reddit_jsonl(dataset_path)\n",
    "    engine.build(docs, metas, hnsw_m=16)\n",
    "    print(\"Search engine index built and saved.\")\n",
    "\n",
    "    # Sample search\n",
    "    results = engine.search(\"How do I become more confident?\", top_k=5)\n",
    "    for i, item in enumerate(results, 1):\n",
    "        print(f\"{i}. {item['title']} → {item['url']} (score: {item['score']:.3f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6273c43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advice: ### This post has been marked as safe. Upvoting/downvoting this comment will have no effect. ---\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")\n",
    "\n",
    "rag_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "def local_rag_answer(query: str, context_k: int = 5) -> str:\n",
    "    contexts = engine.search(query, top_k=context_k)\n",
    "\n",
    "    context_texts = [\n",
    "        f\"Title: {c['title']}\\nAdvice: {c.get('top_comment', '')}\"\n",
    "        for c in contexts\n",
    "    ]\n",
    "\n",
    "    prompt_body = \"\\n\\n\".join(context_texts)\n",
    "    prompt = (\n",
    "        f\"Based on the Reddit advice below, answer the QUESTION in 3–5 bullet points.\\n\\n\"\n",
    "        f\"REDDIT ADVICE:\\n{prompt_body}\\n\\nQUESTION: {query}\"\n",
    "    )\n",
    "\n",
    "    # Truncate prompt tokens to fit the model's input limit (512)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    \n",
    "    result = rag_pipeline(prompt, max_length=256, do_sample=True, temperature=0.7, truncation=True)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "\n",
    "\n",
    "print(local_rag_answer(\"How do I become more confident?\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8bf1f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advice: Consistency is key to starting a friendship, that's where school or work can help, because you are forced to be with eachother 5 days a week. Title: LPT If you're an introvert, you don't need to force yourself to become an extrovert to make friends—just embrace your natural traits.\n"
     ]
    }
   ],
   "source": [
    "print(local_rag_answer(\"How do I connect with people?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17d59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
